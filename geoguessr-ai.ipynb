{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeoGuessr Artificial Intelligence Model 🌏🌎🌍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import cv2 as cv \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import folium\n",
    "\n",
    "# globals\n",
    "dataset_rel_path = \"./data/geotagged_kaggle/streetviews/\"\n",
    "STANDARD_IMAGE_SIZE = 256\n",
    "europe_bbox = {\n",
    "    'lat_min': 36.03,\n",
    "    'lat_max': 71.13,\n",
    "    'long_min': -10.72,\n",
    "    'long_max': 41.31\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading 📷"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The used dataset is based on Google Streetview captures tagged with the latitude and longitude (geoTagged). The images are organized into folders based on the country they are taken from (the name of the folder is the country code).\n",
    "\n",
    "This model works with the countries from Europe (from the [UN's point of view](https://www.worldometers.info/geography/how-many-countries-in-europe/)). Excluded Russia as most of its surface is not in Europe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "europe_countries_code_list = [\"AL\", \"AD\", \"AT\", \"BY\", \"BE\", \"BA\", \"BG\", \"HR\", \"CZ\", \"DK\", \"EE\", \"FI\", \"FR\", \"DE\", \"GR\", \"VA\", \"HU\", \"IS\", \"IE\", \"IT\", \"LV\", \"LI\", \"LT\", \"LU\", \"MT\", \"MD\", \"MC\", \"ME\", \"NL\", \"MK\", \"NO\", \"PL\", \"PT\", \"RO\", \"SM\", \"RS\", \"SK\", \"SI\", \"ES\", \"SE\", \"CH\", \"UA\", \"GB\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Insights\n",
    "Let's take a look at the number of images in each folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_nr_images = {}\n",
    "\n",
    "def count_files_in_dir(dir_path):\n",
    "    return len(os.listdir(dir_path))\n",
    "\n",
    "DATASET_ROOT_PATH = os.path.abspath(dataset_rel_path)\n",
    "\n",
    "for country_folder in os.listdir(DATASET_ROOT_PATH):\n",
    "    if (country_folder in europe_countries_code_list):\n",
    "        country_nr_images[country_folder] = len(os.listdir(os.path.join(DATASET_ROOT_PATH, country_folder)))\n",
    "\n",
    "plt.bar(country_nr_images.keys(), country_nr_images.values())\n",
    "plt.xlabel(\"Country\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"Nr of Images\")\n",
    "plt.show()\n",
    "\n",
    "print(\"European countries that are not in the dataset: \")\n",
    "print([elem for elem in list(country_nr_images.keys()) + europe_countries_code_list if elem not in country_nr_images.keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also plot the report of number of images over the total country surface to observe any imbalances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "european_country_surface_areas = {\n",
    "    'AL': 28748,  # Albania\n",
    "    'AD': 468,    # Andorra\n",
    "    'AT': 83879,  # Austria\n",
    "    'BY': 207600, # Belarus\n",
    "    'BE': 30528,  # Belgium\n",
    "    'BA': 51197,  # Bosnia and Herzegovina\n",
    "    'BG': 110879, # Bulgaria\n",
    "    'HR': 56594,  # Croatia\n",
    "    'CY': 9251,   # Cyprus\n",
    "    'CZ': 78865,  # Czech Republic\n",
    "    'DK': 42924,  # Denmark\n",
    "    'EE': 45227,  # Estonia\n",
    "    'FI': 338424, # Finland\n",
    "    'FR': 551695, # France\n",
    "    'DE': 357022, # Germany\n",
    "    'GR': 131957, # Greece\n",
    "    'HU': 93030,  # Hungary\n",
    "    'IS': 103000, # Iceland\n",
    "    'IE': 70273,  # Ireland\n",
    "    'IT': 301340, # Italy\n",
    "    'LV': 64589,  # Latvia\n",
    "    'LI': 160,    # Liechtenstein\n",
    "    'LT': 65300,  # Lithuania\n",
    "    'LU': 2586,   # Luxembourg\n",
    "    'MK': 25713,  # North Macedonia\n",
    "    'MT': 316,    # Malta\n",
    "    'MD': 33843,  # Moldova\n",
    "    'MC': 2,      # Monaco\n",
    "    'ME': 13812,  # Montenegro\n",
    "    'NL': 41543,  # Netherlands\n",
    "    'NO': 1487290,# Norway\n",
    "    'PL': 312696, # Poland\n",
    "    'PT': 92212,  # Portugal\n",
    "    'RO': 238397, # Romania\n",
    "    'RU': 17098242,# Russia\n",
    "    'SM': 61,     # San Marino\n",
    "    'RS': 77474,  # Serbia\n",
    "    'SK': 49037,  # Slovakia\n",
    "    'SI': 20273,  # Slovenia\n",
    "    'ES': 505992, # Spain\n",
    "    'SE': 450295, # Sweden\n",
    "    'CH': 41284,  # Switzerland\n",
    "    'UA': 603500, # Ukraine\n",
    "    'GB': 243610, # United Kingdom\n",
    "    'VA': 0.44,   # Vatican City\n",
    "}\n",
    "\n",
    "filtered_european_country_surface_areas = {key: european_country_surface_areas[key] for key in country_nr_images.keys()}\n",
    "\n",
    "for country_code in country_nr_images.keys():\n",
    "    filtered_european_country_surface_areas[country_code] = country_nr_images[country_code] / filtered_european_country_surface_areas[country_code] * 100\n",
    "\n",
    "plt.bar(country_nr_images.keys(), filtered_european_country_surface_areas.values())\n",
    "plt.xlabel(\"Country\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"Nr of Images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the geographic distribution of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_data = {\n",
    "    'path': [],\n",
    "    'long': [],\n",
    "    'lat': []\n",
    "}\n",
    "for country_folder in os.listdir(DATASET_ROOT_PATH):\n",
    "    if (country_folder in europe_countries_code_list):\n",
    "        curr_path = os.path.join(DATASET_ROOT_PATH, country_folder)\n",
    "        for filename in os.listdir(curr_path):\n",
    "            curr_lat, curr_long = filename[: -4].split(',')\n",
    "            coordinates_data['path'].append(os.path.join(curr_path, filename))\n",
    "            coordinates_data['lat'].append(float(curr_lat))\n",
    "            coordinates_data['long'].append(float(curr_long))\n",
    "all_countries_df = pd.DataFrame(coordinates_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_map = None\n",
    "# map_center = [45, 15]\n",
    "# my_map = folium.Map(location=map_center, zoom_start=5)\n",
    "\n",
    "\n",
    "# # Add markers for each coordinate\n",
    "# for coordinates in list(zip(all_countries_df.lat, all_countries_df.long)):\n",
    "#     folium.CircleMarker(location=(coordinates[0], coordinates[1]), radius=1).add_to(my_map)\n",
    "\n",
    "# # Save the map as an HTML file\n",
    "# my_map.save(\"map_with_markers.html\")\n",
    "# my_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Questions to solve\n",
    "> - how to treat areas with no data\n",
    "> - how to create the areas that determine the prediction\n",
    ">     - how to ensure it's only land (check geopandas) - not so much of a problem though, as long as the square is not only on sea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling and splitting into Test, Validation, and Training sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Each folder contents will be split into training, validation and test datasets having the percentage 80%, 10%, 10% respectively.\n",
    "\n",
    "### Storing the training data in memory\n",
    "#### Data preprocessing\n",
    "Preprocessing is strongly tied to the choice of the model used (CNN / Vision transformer / Deep neural networks), therefore it may be adapted later in the implementation\n",
    "\n",
    "Let us first prepare the input data for being fed into a Convolutional Neural Network. This type of network expects a 4D Tensor. For a colored image, this tensor would have the shape\n",
    "```\n",
    "[BATCH_SIZE, IMAGE_HEIGHT, IMAGE_WIDTH, NUMBER_OF_CHANNELS]\n",
    "```\n",
    "\n",
    "The images will be preprocessed as follows:\n",
    "- resize to the STANDARD_SIZE in this case 256 pixels for an edge (square shape)\n",
    "- normalize the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV understanding on how images are processed\n",
    "\n",
    "example_img = cv.imread(os.path.join(dataset_rel_path, \"CH/45.72656,6.52431.jpg\"))\n",
    "print(type(example_img))\n",
    "print(np.shape(example_img))\n",
    "\n",
    "# resize\n",
    "resized = cv.resize(example_img, (STANDARD_IMAGE_SIZE, STANDARD_IMAGE_SIZE), interpolation=cv.INTER_NEAREST)\n",
    "print(np.shape(resized))\n",
    "print(resized[0][0]) # print the color channels B G R\n",
    "\n",
    "# cv.imshow(\"original\", example_img)\n",
    "# cv.imshow(\"resized\", resized)\n",
    "# cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Labeling, creating the csv dataset, splitting into test, train, validation sets\n",
    "We need to get from the current state of the data to the data suitable for training, validation and testing.\n",
    "- *current* state: jpg images aranged into folders and labeled with their latitude and longitude values \n",
    "- *desired* state: individual examples consisting of numpy arrays of the required shape, populated with the RGB channels values, and labeled with an integer corresponding to the area on the map where they belong.\n",
    "\n",
    "Data Structures for the Images:\n",
    "- x_train, x_validate, x_test: arrays containing the pixel data of the images (will be fed into the neural network)\n",
    "- y_train, y_validate, y_test: arrays containing the label of each example.\n",
    "\n",
    "> Note: The label and the example need to be at the same index in the data structures that hold them. Therefore, they need to be shuffled together\n",
    "\n",
    "##### Obtaining the output labels ⏹\n",
    "In this method the map of europe will be divided into square shapes, therefore the label of an image is the index of the square into the ordered list of squares. The size of the square is determined by the number of training examples in that square. Therefore if it exceeds the `THRESHOLD` it will be split into 4 (its size is reduced). Obtaining these squares is a subproblem on its own and will be solved in the following part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will break up square -10.72 36.03 10 744\n",
      "will break up square  -10.72 36.03 5.0 325\n",
      "will break up square  -10.72 41.03 5.0 304\n",
      "will break up square -10.72 46.03 10 678\n",
      "will break up square  -5.720000000000001 51.03 5.0 338\n",
      "will break up square -0.7200000000000006 36.03 10 542\n",
      "will break up square  4.279999999999999 41.03 5.0 319\n",
      "will break up square -0.7200000000000006 46.03 10 1493\n",
      "will break up square  -0.7200000000000006 46.03 5.0 384\n",
      "will break up square  1.7799999999999994 48.53 2.5 324\n",
      "will break up square  4.279999999999999 46.03 5.0 506\n",
      "will break up square  4.279999999999999 51.03 5.0 332\n",
      "will break up square 9.28 36.03 10 383\n",
      "will break up square 9.28 46.03 10 1384\n",
      "will break up square  14.28 46.03 5.0 874\n",
      "will break up square  16.78 48.53 2.5 462\n",
      "will break up square 19.28 36.03 10 323\n"
     ]
    }
   ],
   "source": [
    "INITIAL_SQUARE_EDGE_SIZE = 10\n",
    "POINTS_IN_SQUARE_TH = 300\n",
    "\n",
    "all_countries_labeled = []\n",
    "\n",
    "def isInBbox(point_coords, bottom_left, size):\n",
    "    if (point_coords[0] > bottom_left[0] and point_coords[0] < bottom_left[0] + size):\n",
    "        if (point_coords[1] > bottom_left[1] and point_coords[1] < bottom_left[1] + size):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def updateLabelForElement(countries_labeled, new_point):\n",
    "    for index, element in enumerate(countries_labeled):\n",
    "        if element['path'] == new_point['path']:\n",
    "            countries_labeled[index]['label'] = new_point['label']\n",
    "            break\n",
    "    return countries_labeled\n",
    "\n",
    "def getSquaresFromArea(countries_labeled, bottom_left, size, points_df, len_squares):\n",
    "    squares_list = []\n",
    "    squares_list_len = 0\n",
    "\n",
    "    bottom_left_x = bottom_left[0]\n",
    "    while bottom_left_x < (bottom_left[0] + 2 * size):\n",
    "        bottom_left_y = bottom_left[1]\n",
    "        while bottom_left_y < (bottom_left[1] + 2 * size):\n",
    "            count_points = 0\n",
    "            curr_points_df = []    \n",
    "            for index, point in all_countries_df.iterrows():\n",
    "                if isInBbox((point['long'], point['lat']), (bottom_left_x, bottom_left_y), size):\n",
    "                    count_points += 1\n",
    "                    curr_points_df.append(point)\n",
    "                    new_point = {\n",
    "                        'path': point['path'],\n",
    "                        'label': len_squares + squares_list_len\n",
    "                    }\n",
    "                    countries_labeled = updateLabelForElement(countries_labeled, new_point)\n",
    "\n",
    "            if count_points >= POINTS_IN_SQUARE_TH:\n",
    "                # break up the square even more\n",
    "                print('will break up square ', bottom_left_x, bottom_left_y, size, count_points)\n",
    "                countries_labeled, squares_list_from_area = (getSquaresFromArea(countries_labeled, (bottom_left_x, bottom_left_y), size / 2, points_df, len_squares + squares_list_len))\n",
    "                squares_list_len += len(squares_list_from_area)\n",
    "                squares_list += squares_list_from_area\n",
    "\n",
    "            elif count_points > 0:\n",
    "                squares_list.append((bottom_left_x, bottom_left_y, size))\n",
    "                squares_list_len += 1\n",
    "            bottom_left_y += size\n",
    "        bottom_left_x += size\n",
    "    return countries_labeled, squares_list\n",
    "\n",
    "\n",
    "\n",
    "squares = []\n",
    "squares_len = 0\n",
    "\n",
    "bottom_left_x = europe_bbox['long_min']\n",
    "while(bottom_left_x < europe_bbox['long_max']):\n",
    "    bottom_left_y = europe_bbox['lat_min']\n",
    "\n",
    "    while (bottom_left_y < europe_bbox['lat_max']):\n",
    "        count_points = 0\n",
    "        curr_points_df = []\n",
    "        \n",
    "        for index, point in all_countries_df.iterrows():\n",
    "            if isInBbox((point['long'], point['lat']), (bottom_left_x, bottom_left_y), INITIAL_SQUARE_EDGE_SIZE):\n",
    "                curr_points_df.append(point)\n",
    "                count_points += 1\n",
    "                point['label'] = squares_len\n",
    "                all_countries_labeled.append(point)\n",
    "\n",
    "        if count_points >= POINTS_IN_SQUARE_TH:\n",
    "            # break the square even more\n",
    "            print('will break up square', bottom_left_x, bottom_left_y, INITIAL_SQUARE_EDGE_SIZE, count_points)\n",
    "            all_countries_labeled, squares_in_area = getSquaresFromArea(all_countries_labeled, (bottom_left_x, bottom_left_y), INITIAL_SQUARE_EDGE_SIZE / 2, pd.DataFrame(curr_points_df), squares_len)\n",
    "            squares_len += len(squares_in_area)\n",
    "            squares += squares_in_area\n",
    "\n",
    "        elif (count_points > 0):\n",
    "            squares.append((bottom_left_x, bottom_left_y, INITIAL_SQUARE_EDGE_SIZE))\n",
    "            squares_len += 1\n",
    "        \n",
    "        bottom_left_y += INITIAL_SQUARE_EDGE_SIZE\n",
    "    \n",
    "    bottom_left_x += INITIAL_SQUARE_EDGE_SIZE\n",
    "       \n",
    "labeled_examples_df = pd.DataFrame(all_countries_labeled) # {path to image, label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-10.72, 36.03, 2.5), (-10.72, 38.53, 2.5), (-8.22, 36.03, 2.5), (-8.22, 38.53, 2.5), (-10.72, 41.03, 2.5), (-8.22, 41.03, 2.5), (-8.22, 43.53, 2.5), (-5.720000000000001, 36.03, 5.0), (-5.720000000000001, 41.03, 5.0), (-10.72, 51.03, 5.0), (-5.720000000000001, 46.03, 5.0), (-5.720000000000001, 51.03, 2.5), (-5.720000000000001, 53.53, 2.5), (-3.2200000000000006, 51.03, 2.5), (-3.2200000000000006, 53.53, 2.5), (-10.72, 56.03, 10), (-0.7200000000000006, 36.03, 5.0), (-0.7200000000000006, 41.03, 5.0), (4.279999999999999, 36.03, 5.0), (4.279999999999999, 41.03, 2.5), (4.279999999999999, 43.53, 2.5), (6.779999999999999, 41.03, 2.5), (6.779999999999999, 43.53, 2.5), (-0.7200000000000006, 46.03, 2.5), (-0.7200000000000006, 48.53, 2.5), (1.7799999999999994, 46.03, 2.5), (1.7799999999999994, 48.53, 1.25), (1.7799999999999994, 49.78, 1.25), (3.0299999999999994, 48.53, 1.25), (3.0299999999999994, 49.78, 1.25), (-0.7200000000000006, 51.03, 5.0), (4.279999999999999, 46.03, 2.5), (4.279999999999999, 48.53, 2.5), (6.779999999999999, 46.03, 2.5), (6.779999999999999, 48.53, 2.5), (4.279999999999999, 51.03, 2.5), (6.779999999999999, 51.03, 2.5), (9.28, 36.03, 5.0), (9.28, 41.03, 5.0), (14.28, 36.03, 5.0), (14.28, 41.03, 5.0), (9.28, 46.03, 5.0), (9.28, 51.03, 5.0), (14.28, 46.03, 2.5), (14.28, 48.53, 2.5), (16.78, 46.03, 2.5), (16.78, 48.53, 1.25), (16.78, 49.78, 1.25), (18.03, 48.53, 1.25), (18.03, 49.78, 1.25), (14.28, 51.03, 5.0), (9.28, 56.03, 10), (9.28, 66.03, 10), (19.28, 41.03, 5.0), (24.28, 41.03, 5.0), (19.28, 46.03, 10), (19.28, 56.03, 10), (19.28, 66.03, 10), (29.28, 46.03, 10)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>c:\\Facultate\\An_4\\An_4_Sem_1\\Pattern_Recogniti...</td>\n",
       "      <td>-3.82138</td>\n",
       "      <td>36.75474</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>c:\\Facultate\\An_4\\An_4_Sem_1\\Pattern_Recogniti...</td>\n",
       "      <td>-4.03624</td>\n",
       "      <td>36.75578</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>c:\\Facultate\\An_4\\An_4_Sem_1\\Pattern_Recogniti...</td>\n",
       "      <td>-3.99454</td>\n",
       "      <td>36.82382</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>c:\\Facultate\\An_4\\An_4_Sem_1\\Pattern_Recogniti...</td>\n",
       "      <td>-5.80706</td>\n",
       "      <td>36.86894</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>c:\\Facultate\\An_4\\An_4_Sem_1\\Pattern_Recogniti...</td>\n",
       "      <td>-5.93936</td>\n",
       "      <td>36.97951</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6434</th>\n",
       "      <td>c:\\Facultate\\An_4\\An_4_Sem_1\\Pattern_Recogniti...</td>\n",
       "      <td>33.59659</td>\n",
       "      <td>51.83715</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6435</th>\n",
       "      <td>c:\\Facultate\\An_4\\An_4_Sem_1\\Pattern_Recogniti...</td>\n",
       "      <td>33.49617</td>\n",
       "      <td>51.85592</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6436</th>\n",
       "      <td>c:\\Facultate\\An_4\\An_4_Sem_1\\Pattern_Recogniti...</td>\n",
       "      <td>33.46536</td>\n",
       "      <td>51.85798</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6437</th>\n",
       "      <td>c:\\Facultate\\An_4\\An_4_Sem_1\\Pattern_Recogniti...</td>\n",
       "      <td>33.46921</td>\n",
       "      <td>51.86084</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6438</th>\n",
       "      <td>c:\\Facultate\\An_4\\An_4_Sem_1\\Pattern_Recogniti...</td>\n",
       "      <td>33.47983</td>\n",
       "      <td>51.86134</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6406 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path      long       lat  \\\n",
       "1681  c:\\Facultate\\An_4\\An_4_Sem_1\\Pattern_Recogniti...  -3.82138  36.75474   \n",
       "1682  c:\\Facultate\\An_4\\An_4_Sem_1\\Pattern_Recogniti...  -4.03624  36.75578   \n",
       "1683  c:\\Facultate\\An_4\\An_4_Sem_1\\Pattern_Recogniti...  -3.99454  36.82382   \n",
       "1684  c:\\Facultate\\An_4\\An_4_Sem_1\\Pattern_Recogniti...  -5.80706  36.86894   \n",
       "1685  c:\\Facultate\\An_4\\An_4_Sem_1\\Pattern_Recogniti...  -5.93936  36.97951   \n",
       "...                                                 ...       ...       ...   \n",
       "6434  c:\\Facultate\\An_4\\An_4_Sem_1\\Pattern_Recogniti...  33.59659  51.83715   \n",
       "6435  c:\\Facultate\\An_4\\An_4_Sem_1\\Pattern_Recogniti...  33.49617  51.85592   \n",
       "6436  c:\\Facultate\\An_4\\An_4_Sem_1\\Pattern_Recogniti...  33.46536  51.85798   \n",
       "6437  c:\\Facultate\\An_4\\An_4_Sem_1\\Pattern_Recogniti...  33.46921  51.86084   \n",
       "6438  c:\\Facultate\\An_4\\An_4_Sem_1\\Pattern_Recogniti...  33.47983  51.86134   \n",
       "\n",
       "      label  \n",
       "1681      7  \n",
       "1682      7  \n",
       "1683      7  \n",
       "1684      2  \n",
       "1685      2  \n",
       "...     ...  \n",
       "6434     58  \n",
       "6435     58  \n",
       "6436     58  \n",
       "6437     58  \n",
       "6438     58  \n",
       "\n",
       "[6406 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(squares)\n",
    "labeled_examples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_center = [45, 15]\n",
    "my_map = folium.Map(location=map_center, zoom_start=5)\n",
    "\n",
    "for index, square in enumerate(squares):\n",
    "    folium.Rectangle(\n",
    "        bounds=[[square[1], square[0]], [square[1] + square[2], square[0] + square[2]]], # long lat (y x)\n",
    "        fill=False,\n",
    "        color='orange',\n",
    "        fill_color='orange',\n",
    "        fill_opacity=0.1,\n",
    "        popup=f'{index}'\n",
    "    ).add_to(my_map)\n",
    "\n",
    "# Add markers for each coordinate\n",
    "for coordinates in list(zip(labeled_examples_df.lat, labeled_examples_df.long, labeled_examples_df.label)):\n",
    "    folium.CircleMarker(location=(coordinates[0], coordinates[1]), radius=2, popup=coordinates[2]).add_to(my_map)\n",
    "\n",
    "\n",
    "my_map.save('map_with_grid.html') # squares appear as rectangles due to map projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 640, 3)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Augmentation\n",
    "The existing images will be added variations including shifted, rotated, zoomed-in/out images, brightened/darkened"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_si",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
